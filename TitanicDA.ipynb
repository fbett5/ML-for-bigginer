{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21ea0fc1",
   "metadata": {},
   "source": [
    "4 hands-on projects that help master the core skills in machine learning , including:\n",
    "\n",
    "âœ… Data cleaning & preprocessing\n",
    "âœ… Feature engineering\n",
    "âœ… Train/test split\n",
    "âœ… Logistic regression or random forest\n",
    "âœ… Model evaluation (accuracy, confusion matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc834688",
   "metadata": {},
   "source": [
    "Project 1: Titanic Survival Prediction\n",
    "ðŸŽ¯ Objective:\n",
    "Predict whether a passenger survived the Titanic disaster using features like age, gender, and class.\n",
    "\n",
    "ðŸ”§ Skills Practiced:\n",
    "    Data cleaning & missing value handling\n",
    "    Categorical encoding\n",
    "    Feature selection/engineering\n",
    "    Train/test split\n",
    "    Random Forest / Logistic Regression\n",
    "    Model evaluation (accuracy, confusion matrix)\n",
    "ðŸ›  Tools Used:\n",
    "    Python\n",
    "    pandas, numpy\n",
    "    scikit-learn\n",
    "    Jupyter Notebook\n",
    "    Dataset from Kaggle/Stanford University "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b474488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Survived  Pclass                                                Name     Sex   Age  Siblings/Spouses Aboard  Parents/Children Aboard     Fare\n",
      "0         0       3                              Mr. Owen Harris Braund    male  22.0                        1                        0   7.2500\n",
      "1         1       1  Mrs. John Bradley (Florence Briggs Thayer) Cumings  female  38.0                        1                        0  71.2833\n",
      "2         1       3                               Miss. Laina Heikkinen  female  26.0                        0                        0   7.9250\n",
      "3         1       1         Mrs. Jacques Heath (Lily May Peel) Futrelle  female  35.0                        1                        0  53.1000\n",
      "4         0       3                             Mr. William Henry Allen    male  35.0                        0                        0   8.0500\n",
      "     Survived  Pclass                            Name     Sex   Age  Siblings/Spouses Aboard  Parents/Children Aboard   Fare\n",
      "882         0       2            Rev. Juozas Montvila    male  27.0                        0                        0  13.00\n",
      "883         1       1     Miss. Margaret Edith Graham  female  19.0                        0                        0  30.00\n",
      "884         0       3  Miss. Catherine Helen Johnston  female   7.0                        1                        2  23.45\n",
      "885         1       1            Mr. Karl Howell Behr    male  26.0                        0                        0  30.00\n",
      "886         0       3              Mr. Patrick Dooley    male  32.0                        0                        0   7.75\n"
     ]
    }
   ],
   "source": [
    "#Import necessary libraries (pandas for data manipulation)\n",
    "import pandas as pd\n",
    "\n",
    "#Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(\"C:/Users/festu/ML05102025/myML/titanic.csv\")\n",
    "\n",
    "#Display the first 5 rows of the DataFrame in a more readable format\n",
    "print(df.head().to_string())\n",
    "\n",
    "#Display last 5 rows of the DataFrame in a more readable format\n",
    "print(df.tail().to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585e8b72",
   "metadata": {},
   "source": [
    "**Step 2: Clean and Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c486ac",
   "metadata": {},
   "source": [
    "***Understanding what we are dealing with***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "280afe58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(887, 8)\n",
      "Survived                     int64\n",
      "Pclass                       int64\n",
      "Name                        object\n",
      "Sex                         object\n",
      "Age                        float64\n",
      "Siblings/Spouses Aboard      int64\n",
      "Parents/Children Aboard      int64\n",
      "Fare                       float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Display the shape of the DataFrame (number of rows and columns)\n",
    "print(df.shape)\n",
    "\n",
    "#Display the data types of each column in the DataFrame\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "355da91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Survived  Pclass     Sex   Age  Siblings/Spouses Aboard  Parents/Children Aboard     Fare\n",
      "0         0       3    male  22.0                        1                        0   7.2500\n",
      "1         1       1  female  38.0                        1                        0  71.2833\n",
      "2         1       3  female  26.0                        0                        0   7.9250\n",
      "3         1       1  female  35.0                        1                        0  53.1000\n",
      "4         0       3    male  35.0                        0                        0   8.0500\n"
     ]
    }
   ],
   "source": [
    "#We need to drop the attributes that are not useful for our analysis: name\n",
    "#Drop the 'Name' column from the DataFrame \n",
    "df.drop(columns=['Name'], inplace=True) # inplace=True modifies the original DataFrame without creating a copy\n",
    "\n",
    "#Display the first 5 rows of the modified DataFrame and convert it to a string for better readability\n",
    "print(df.head().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3cbd6c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived                   0\n",
      "Pclass                     0\n",
      "Sex                        0\n",
      "Age                        0\n",
      "Siblings/Spouses Aboard    0\n",
      "Parents/Children Aboard    0\n",
      "Fare                       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#lets check if thereare any missing values in the dataset\n",
    "print(df.isnull().sum()) #O missing values in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8340588a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Survived  Pclass  Sex   Age  Siblings/Spouses Aboard  Parents/Children Aboard     Fare\n",
      "0         0       3    1  22.0                        1                        0   7.2500\n",
      "1         1       1    0  38.0                        1                        0  71.2833\n",
      "2         1       3    0  26.0                        0                        0   7.9250\n",
      "3         1       1    0  35.0                        1                        0  53.1000\n",
      "4         0       3    1  35.0                        0                        0   8.0500\n"
     ]
    }
   ],
   "source": [
    "#Lets import the libraries for encording data from categorical to numerical (sex)\n",
    "from sklearn.preprocessing import LabelEncoder #for encoding categorical variables need to install sklearn, pip install -U scikit-learn\n",
    "\n",
    "le = LabelEncoder() #create an instance of the LabelEncoder class\n",
    "#Encode the sex column (categorical variable) into numerical values\n",
    "df[\"Sex\"] = le.fit_transform(df['Sex']) #fit_transform() method fits the encoder and transforms the data in one step\n",
    "\n",
    "#Display the first 5 rows of the DataFrame after encoding\n",
    "print(df.head().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bc04d7fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Survived  Pclass  Sex   Age  Siblings/Spouses Aboard  Parents/Children Aboard     Fare\n",
      "0         0       3    1  22.0                        1                        0   7.2500\n",
      "1         1       1    0  38.0                        1                        0  71.2833\n",
      "2         1       3    0  26.0                        0                        0   7.9250\n",
      "3         1       1    0  35.0                        1                        0  53.1000\n",
      "4         0       3    1  35.0                        0                        0   8.0500\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(df.head().to_string()) #Display the first 5 rows of the modified DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01acd28d",
   "metadata": {},
   "source": [
    "**Step 3: Train/Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d426bf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the libraries for needed for training the model\n",
    "from sklearn.model_selection import train_test_split #for splitting the dataset into training and testing sets\n",
    "\n",
    "#Drop the Survived column from the DataFrame to create the feature set (X)\n",
    "X = df.drop(columns=['Survived']) #X will contain all columns except 'Survived'\n",
    "#Create the target variable (y) by selecting the Survived column\n",
    "y = df['Survived'] #y will contain only the 'Survived' column\n",
    "\n",
    "#Split the dataset into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) #random_state ensures reproducibility of the split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090dc58b",
   "metadata": {},
   "source": [
    "**Step 4: Train Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a0856438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use the Random Forest Classifier for our model\n",
    "from sklearn.ensemble import RandomForestClassifier #for the Random Forest Classifier\n",
    "\n",
    "#Create an instance of the RandomForestClassifier with 100 trees\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42) #n_estimators specifies the number of trees in the forest\n",
    "#Train the model using the training data\n",
    "model.fit(X_train, y_train) #fit() method trains the model on the training data\n",
    "#Make predictions on the test data\n",
    "y_pred = model.predict(X_test) #predict() method generates predictions for the test data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41c8687",
   "metadata": {},
   "source": [
    "**Step 5: Printing Predictions vs Actual Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a2432dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Actual  Predicted\n",
      "296       1          0\n",
      "682       0          0\n",
      "535       0          0\n",
      "644       1          0\n",
      "623       0          0\n",
      "39        1          1\n",
      "529       0          0\n",
      "585       0          0\n",
      "723       1          1\n",
      "141       1          0\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test data\n",
    "y_pred = model.predict(X_test) #predict() method generates predictions for the test data\n",
    "\n",
    "#comparing the first 10 predictions with the actual values\n",
    "comp_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred}) #create a DataFrame to compare actual and predicted values\n",
    "\n",
    "#printing the firdt 10 rows of the comparison DataFrame\n",
    "print(comp_df.head(10).to_string()) #Display the first 10 rows of the comparison DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5448f63",
   "metadata": {},
   "source": [
    "**Step 6: Evaluating the Modeland checking the Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "64d3a2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81       111\n",
      "           1       0.69      0.67      0.68        67\n",
      "\n",
      "    accuracy                           0.76       178\n",
      "   macro avg       0.75      0.75      0.75       178\n",
      "weighted avg       0.76      0.76      0.76       178\n",
      "\n",
      "Accuracy: 0.7640449438202247\n",
      "Confusion Matrix:\n",
      " [[91 20]\n",
      " [22 45]]\n"
     ]
    }
   ],
   "source": [
    "#import the libraries for evaluating the model\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score #for generating classification report and confusion matrix\n",
    "\n",
    "preds = model.predict(X_test) #make predictions on the test data\n",
    "#Generate the classification report\n",
    "print(classification_report(y_test, preds)) #classification_report() generates a report showing the main classification metrics\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, preds)) #accuracy_score() calculates the accuracy of the model\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, preds)) #confusion_matrix() generates a confusion matrix to evaluate the performance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab406c1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
